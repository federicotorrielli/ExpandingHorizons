{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade55bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 27 08:54:31 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   25C    P0              51W / 400W |      2MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-80GB          On  | 00000000:00:06.0 Off |                    0 |\n",
      "| N/A   25C    P0              50W / 400W |      2MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "Filesystem                  Use% Avail\n",
      "tmpfs                         1%   18G\n",
      "/dev/mapper/ubuntu--vg-root  95%   25G\n",
      "tmpfs                         0%   89G\n",
      "tmpfs                         0%    1G\n",
      "/dev/xvda2                   27%    2G\n",
      "tmpfs                         1%   18G\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!df --output=source,pcent,avail -BG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db19304f-7461-43ef-80b4-d8b48914842c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T12:42:19.038977Z",
     "iopub.status.busy": "2023-10-18T12:42:19.038058Z",
     "iopub.status.idle": "2023-10-18T12:42:22.514569Z",
     "shell.execute_reply": "2023-10-18T12:42:22.513822Z",
     "shell.execute_reply.started": "2023-10-18T12:42:19.038947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vllm in ./miniforge3/envs/semagram/lib/python3.10/site-packages (0.2.1.post1)\n",
      "Requirement already satisfied: ujson in ./miniforge3/envs/semagram/lib/python3.10/site-packages (5.8.0)\n",
      "Requirement already satisfied: tqdm in ./miniforge3/envs/semagram/lib/python3.10/site-packages (4.66.1)\n",
      "Requirement already satisfied: ninja in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from vllm) (1.11.1.1)\n",
      "Requirement already satisfied: psutil in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from vllm) (5.9.5)\n",
      "Requirement already satisfied: ray>=2.5.1 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from vllm) (2.7.1)\n",
      "Requirement already satisfied: pandas in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from vllm) (2.1.1)\n",
      "Requirement already satisfied: pyarrow in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from vllm) (13.0.0)\n",
      "Requirement already satisfied: sentencepiece in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from vllm) (0.1.99)\n",
      "Requirement already satisfied: numpy in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from vllm) (1.26.1)\n",
      "Requirement already satisfied: torch==2.0.1 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from vllm) (2.0.1)\n",
      "Requirement already satisfied: transformers>=4.34.0 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from vllm) (4.34.1)\n",
      "Requirement already satisfied: xformers==0.0.22 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from vllm) (0.0.22)\n",
      "Requirement already satisfied: fastapi in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from vllm) (0.104.0)\n",
      "Requirement already satisfied: uvicorn[standard] in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from vllm) (0.23.2)\n",
      "Requirement already satisfied: pydantic<2 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from vllm) (1.10.13)\n",
      "Requirement already satisfied: filelock in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (4.8.0)\n",
      "Requirement already satisfied: sympy in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (1.12)\n",
      "Requirement already satisfied: networkx in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (3.2)\n",
      "Requirement already satisfied: jinja2 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from torch==2.0.1->vllm) (2.0.0)\n",
      "Requirement already satisfied: setuptools in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->vllm) (68.2.2)\n",
      "Requirement already satisfied: wheel in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->vllm) (0.41.2)\n",
      "Requirement already satisfied: cmake in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->vllm) (3.27.7)\n",
      "Requirement already satisfied: lit in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->vllm) (17.0.3)\n",
      "Requirement already satisfied: click>=7.0 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from ray>=2.5.1->vllm) (8.1.7)\n",
      "Requirement already satisfied: jsonschema in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from ray>=2.5.1->vllm) (4.19.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from ray>=2.5.1->vllm) (1.0.7)\n",
      "Requirement already satisfied: packaging in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from ray>=2.5.1->vllm) (23.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from ray>=2.5.1->vllm) (4.24.4)\n",
      "Requirement already satisfied: pyyaml in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from ray>=2.5.1->vllm) (6.0.1)\n",
      "Requirement already satisfied: aiosignal in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from ray>=2.5.1->vllm) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from ray>=2.5.1->vllm) (1.4.0)\n",
      "Requirement already satisfied: requests in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from ray>=2.5.1->vllm) (2.31.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from transformers>=4.34.0->vllm) (0.17.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from transformers>=4.34.0->vllm) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from transformers>=4.34.0->vllm) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from transformers>=4.34.0->vllm) (0.4.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from fastapi->vllm) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from fastapi->vllm) (0.27.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from pandas->vllm) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from pandas->vllm) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from pandas->vllm) (2023.3)\n",
      "Requirement already satisfied: h11>=0.8 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (1.0.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (12.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->vllm) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->vllm) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->vllm) (1.1.3)\n",
      "Requirement already satisfied: fsspec in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.34.0->vllm) (2023.10.0)\n",
      "Requirement already satisfied: six>=1.5 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->vllm) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from jinja2->torch==2.0.1->vllm) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from jsonschema->ray>=2.5.1->vllm) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from jsonschema->ray>=2.5.1->vllm) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from jsonschema->ray>=2.5.1->vllm) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from jsonschema->ray>=2.5.1->vllm) (0.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from requests->ray>=2.5.1->vllm) (3.3.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from requests->ray>=2.5.1->vllm) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from requests->ray>=2.5.1->vllm) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./miniforge3/envs/semagram/lib/python3.10/site-packages (from sympy->torch==2.0.1->vllm) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/paperspace/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "%pip install -U vllm ujson tqdm\n",
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faea4cdd-34ae-4bc8-80b5-1719ece0cb95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T12:44:31.909335Z",
     "iopub.status.busy": "2023-10-18T12:44:31.908329Z",
     "iopub.status.idle": "2023-10-18T12:44:31.913186Z",
     "shell.execute_reply": "2023-10-18T12:44:31.912696Z",
     "shell.execute_reply.started": "2023-10-18T12:44:31.909295Z"
    }
   },
   "outputs": [],
   "source": [
    "import ujson\n",
    "import torch\n",
    "import time\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from vllm import LLM, SamplingParams\n",
    "from vllm.model_executor.parallel_utils.parallel_state import destroy_model_parallel\n",
    "\n",
    "model_names = [\n",
    "                #\"BAAI/Aquila2-7B\",\n",
    "                #\"databricks/dolly-v2-12b\",\n",
    "                #\"mistralai/Mistral-7B-v0.1\",\n",
    "                #\"meta-llama/Llama-2-13b-hf\",\n",
    "                #\"lmsys/vicuna-13b-v1.5\",\n",
    "                # \"mosaicml/mpt-30b-instruct\",\n",
    "                \"tiiuae/falcon-40b\",\n",
    "               ]\n",
    "\n",
    "sampling_params = SamplingParams(top_p=0.9, temperature=0.35, max_tokens=50)\n",
    "\n",
    "t = sampling_params.temperature\n",
    "top_p = sampling_params.top_p\n",
    "max_new_tokens = sampling_params.max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c109c7f6-8e22-4264-9cd4-c019e719951d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T12:42:43.798374Z",
     "iopub.status.busy": "2023-10-18T12:42:43.797751Z",
     "iopub.status.idle": "2023-10-18T12:42:43.811908Z",
     "shell.execute_reply": "2023-10-18T12:42:43.811009Z",
     "shell.execute_reply.started": "2023-10-18T12:42:43.798344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-27 08:54:40--  https://evilscript.eu/upload/files/zero_shot_prompt_v2.json\n",
      "Resolving evilscript.eu (evilscript.eu)... 89.46.105.45\n",
      "Connecting to evilscript.eu (evilscript.eu)|89.46.105.45|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://www.evilscript.eu/upload/files/zero_shot_prompt_v2.json [following]\n",
      "--2023-10-27 08:54:41--  https://www.evilscript.eu/upload/files/zero_shot_prompt_v2.json\n",
      "Resolving www.evilscript.eu (www.evilscript.eu)... 89.46.105.45\n",
      "Connecting to www.evilscript.eu (www.evilscript.eu)|89.46.105.45|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1377348 (1.3M) [application/json]\n",
      "Saving to: ‘zero_shot_prompt_v2.json.1’\n",
      "\n",
      "zero_shot_prompt_v2 100%[===================>]   1.31M  2.54MB/s    in 0.5s    \n",
      "\n",
      "2023-10-27 08:54:42 (2.54 MB/s) - ‘zero_shot_prompt_v2.json.1’ saved [1377348/1377348]\n",
      "\n",
      "--2023-10-27 08:54:42--  https://evilscript.eu/upload/files/zero_shot_prompt_v1.json\n",
      "Resolving evilscript.eu (evilscript.eu)... 89.46.105.45\n",
      "Connecting to evilscript.eu (evilscript.eu)|89.46.105.45|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://www.evilscript.eu/upload/files/zero_shot_prompt_v1.json [following]\n",
      "--2023-10-27 08:54:43--  https://www.evilscript.eu/upload/files/zero_shot_prompt_v1.json\n",
      "Resolving www.evilscript.eu (www.evilscript.eu)... 89.46.105.45\n",
      "Connecting to www.evilscript.eu (www.evilscript.eu)|89.46.105.45|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1403682 (1.3M) [application/json]\n",
      "Saving to: ‘zero_shot_prompt_v1.json.1’\n",
      "\n",
      "zero_shot_prompt_v1 100%[===================>]   1.34M  2.53MB/s    in 0.5s    \n",
      "\n",
      "2023-10-27 08:54:45 (2.53 MB/s) - ‘zero_shot_prompt_v1.json.1’ saved [1403682/1403682]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_number_prompts(file):\n",
    "  with open(file, 'r') as reader:\n",
    "    all_data = ujson.load(reader)\n",
    "    counter = 0\n",
    "    for _ in all_data:\n",
    "      counter += 1\n",
    "    return counter\n",
    "\n",
    "def prompt_generator(file):\n",
    "  with open(file, 'r') as reader:\n",
    "    all_data = ujson.load(reader)\n",
    "    for data in all_data:\n",
    "      yield data[\"cat\"], data[\"slot\"], data[\"value\"], data[\"prompt\"]\n",
    "      \n",
    "def get_only_prompts(file):\n",
    "  with open(file, 'r') as reader:\n",
    "    all_data = ujson.load(reader)\n",
    "    output = []\n",
    "    for data in all_data:\n",
    "      output.append(data[\"prompt\"])\n",
    "    return output\n",
    "\n",
    "def get_all_prompts(file):\n",
    "  with open(file, 'r') as reader:\n",
    "    all_data = ujson.load(reader)\n",
    "    output = []\n",
    "    for data in all_data:\n",
    "      output.append((data[\"cat\"], data[\"slot\"], data[\"value\"], data[\"prompt\"]))\n",
    "    return output\n",
    "\n",
    "def get_simple_model_name(m_name):\n",
    "  if '/' in m_name:\n",
    "    m_name = m_name.split('/')[-1]\n",
    "  return m_name\n",
    "\n",
    "input_f = 'zero_shot_prompt_v2.json'\n",
    "!wget \"https://evilscript.eu/upload/files/zero_shot_prompt_v2.json\"\n",
    "!wget \"https://evilscript.eu/upload/files/zero_shot_prompt_v1.json\"\n",
    "!rm zero_shot_prompt_v1.json.1\n",
    "!rm zero_shot_prompt_v2.json.1\n",
    "num_prompts = get_number_prompts(input_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64765a09-9c88-478d-b261-697f90d00f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T12:44:34.450226Z",
     "iopub.status.busy": "2023-10-18T12:44:34.449539Z",
     "iopub.status.idle": "2023-10-18T12:44:35.379992Z",
     "shell.execute_reply": "2023-10-18T12:44:35.376544Z",
     "shell.execute_reply.started": "2023-10-18T12:44:34.450191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tiiuae/falcon-40b with 3762 prompts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 10-27 08:54:46 config.py:379] The model's config.json does not contain any of the following keys to determine the original maximum length of the model: ['max_position_embeddings', 'n_positions', 'max_seq_len', 'max_sequence_length', 'max_seq_length', 'seq_len']. Assuming the model's maximum length is 2048.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-27 08:54:48,064\tINFO worker.py:1642 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-27 08:54:48 llm_engine.py:72] Initializing an LLM engine with config: model='tiiuae/falcon-40b', tokenizer='tiiuae/falcon-40b', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=2, quantization=None, seed=0)\n",
      "INFO 10-27 08:57:44 llm_engine.py:207] # GPU blocks: 34322, # CPU blocks: 4369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:  98%|█████████████████████████████████████████████████████▊ | 3683/3762 [02:55<00:01, 60.35it/s]\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-10-27 09:00:45,928 E 2323 2342] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-10-27_08-54-46_266921_2162 is over 95% full, available space: 26320977920; capacity: 526452940800. Object creation will fail if spilling is required.\n",
      "Processed prompts: 100%|███████████████████████████████████████████████████████| 3762/3762 [02:57<00:00, 21.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 3762/3762 [00:00<00:00, 205140.17it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-10-27 09:03:05,308 E 2323 2342] (raylet) file_system_monitor.cc:111: /tmp/ray/session_2023-10-27_08-54-46_266921_2162 is over 95% full, available space: 26315038720; capacity: 526452940800. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "  f_m_name = get_simple_model_name(model_name)\n",
    "  file_output = f'{f_m_name}__t_{t}__top_p_{top_p}__max_new_tokens_{max_new_tokens}.jsonl'\n",
    "  \n",
    "  print(f'Running {model_name} with {num_prompts} prompts')\n",
    "  \n",
    "  model = LLM(model_name, trust_remote_code=True, tensor_parallel_size=torch.cuda.device_count())\n",
    "  \n",
    "  with open(file_output, 'w') as writer:\n",
    "    generator = prompt_generator(input_f)\n",
    "    full_list_prompts = get_only_prompts(input_f)\n",
    "    model_outputs = model.generate(full_list_prompts, sampling_params=sampling_params)\n",
    "    outputs_dict = {}\n",
    "    for output in model_outputs:\n",
    "      prompt = output.prompt\n",
    "      generated_text = output.outputs[0].text\n",
    "      outputs_dict[prompt] = generated_text\n",
    "    for (cat, slot, value, prompt) in tqdm(generator, total=num_prompts):\n",
    "      model_output = outputs_dict[prompt]\n",
    "      json_dump = ujson.dumps({\"cat\": cat,\n",
    "                              \"slot\": slot,\n",
    "                              \"value\": value,\n",
    "                              \"prompt\": prompt,\n",
    "                              \"result\": model_output})\n",
    "      writer.write(json_dump + '\\n')\n",
    "    with torch.no_grad():\n",
    "        destroy_model_parallel()\n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        time.sleep(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
